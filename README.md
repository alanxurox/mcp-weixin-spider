# MCP WeChat Spider ğŸ•·ï¸

**English** | [ä¸­æ–‡](README_CN.md)

**No more copy-paste! Let AI directly read WeChat articles via MCP**

An MCP (Model Context Protocol) server that enables AI assistants to directly crawl and analyze WeChat public account articles - no more copy-paste!

## Problem Solved

Have you ever wanted AI to analyze a WeChat article, only to find it can't access the content? The traditional workflow requires:
1. Open WeChat article
2. Copy all text manually
3. Paste into AI chat
4. Lose images and formatting

**This MCP server solves that.** Just give the AI a WeChat URL, and it can:
- Extract full article content (text + HTML)
- Download embedded images
- Analyze article statistics
- Compare multiple articles
- Batch process competitor accounts

## Quick Start

### 1. Install Dependencies

```bash
cd mcp-weixin
pip install -r requirements.txt
```

Or with uv:
```bash
uv pip install -r requirements.txt
```

### 2. Choose Backend

| Backend | Pros | Cons |
|---------|------|------|
| **agent-browser** | Lighter, no Chrome driver needed | Fewer features, needs agent-browser installed |
| **selenium** | Full featured, image downloads | Heavier, needs Chrome/ChromeDriver |

Set via `CRAWLER_BACKEND` env var: `"agentbrowser"` or `"selenium"` (default).

### 3. Configure in Cursor/Claude

Add to your MCP settings (Cursor: Settings â†’ MCP, or `~/.cursor/mcp.json`):

**Option A: agent-browser backend (recommended - lighter weight)**
```json
{
  "mcpServers": {
    "weixin_spider": {
      "command": "python",
      "args": ["/path/to/mcp-weixin/src/mcp_weixin_spider/server.py"],
      "env": {
        "PYTHONPATH": "/path/to/mcp-weixin",
        "CRAWLER_BACKEND": "agentbrowser",
        "AGENT_BROWSER_BIN": "/path/to/agent-browser/bin/agent-browser",
        "WAIT_TIME": "10"
      }
    }
  }
}
```

**Option B: Selenium backend (full features)**
```json
{
  "mcpServers": {
    "weixin_spider": {
      "command": "python",
      "args": ["/path/to/mcp-weixin/src/mcp_weixin_spider/server.py"],
      "env": {
        "PYTHONPATH": "/path/to/mcp-weixin",
        "CRAWLER_BACKEND": "selenium",
        "DOWNLOAD_IMAGES": "true",
        "WAIT_TIME": "10"
      }
    }
  }
}
```

### 3. Use in AI Chat

Once configured, you can ask your AI:

```
å¸®æˆ‘åˆ†æè¿™ç¯‡å…¬ä¼—å·æ–‡ç« : https://mp.weixin.qq.com/s/...
```

The AI will use the MCP tools to crawl and analyze the article directly!

## Available Tools

| Tool | Description |
|------|-------------|
| `crawl_weixin_article` | çˆ¬å–æ–‡ç« å†…å®¹å’Œå›¾ç‰‡ - Full article extraction |
| `analyze_weixin_article` | åˆ†ææ–‡ç« ç»Ÿè®¡æ•°æ® - Statistics and key phrases |
| `summarize_weixin_article` | è·å–æ–‡ç« æ‘˜è¦ - Quick summary |
| `batch_crawl_articles` | æ‰¹é‡çˆ¬å–å¤šç¯‡æ–‡ç«  - Process multiple URLs |
| `compare_articles` | å¯¹æ¯”åˆ†æå¤šç¯‡æ–‡ç«  - Competitive analysis |

## Architecture

```
mcp-weixin/
â”œâ”€â”€ src/mcp_weixin_spider/
â”‚   â”œâ”€â”€ server.py          # FastMCP server (main entry point)
â”‚   â”œâ”€â”€ client.py           # MCP client for testing
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ weixin_spider_simple.py # Core crawler (Selenium/Chrome)
â”œâ”€â”€ pyproject.toml          # Project config
â”œâ”€â”€ requirements.txt        # Dependencies
â””â”€â”€ README.md
```

### How It Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     MCP Protocol    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   AI/LLM    â”‚ â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚  MCP Server  â”‚
â”‚ (Claude/    â”‚    stdio transport  â”‚  (FastMCP)   â”‚
â”‚  Cursor)    â”‚                     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
                                           â–¼
                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                               â”‚   Chrome Driver   â”‚
                               â”‚   (Headless)      â”‚
                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚
                                         â–¼
                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                               â”‚  mp.weixin.qq.com â”‚
                               â”‚   (Articles)      â”‚
                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

1. **AI sends request** via MCP protocol
2. **MCP Server** receives and parses the request
3. **Chrome Driver** loads the WeChat article (headless)
4. **Content extracted** (title, author, text, images)
5. **Results returned** to AI as structured JSON

## Use Cases

### 1. Single Article Analysis
```
ç”¨æˆ·: å¸®æˆ‘æ€»ç»“è¿™ç¯‡æ–‡ç«  https://mp.weixin.qq.com/s/xxx
AI: [calls summarize_weixin_article] è¿™ç¯‡æ–‡ç« ä¸»è¦è®²è¿°äº†...
```

### 2. Competitive Analysis
```
ç”¨æˆ·: å¯¹æ¯”åˆ†æè¿™ä¸‰ä¸ªç«å“å…¬ä¼—å·çš„æœ€æ–°æ–‡ç« 
AI: [calls compare_articles] ä¸‰ç¯‡æ–‡ç« çš„å¯¹æ¯”åˆ†æå¦‚ä¸‹...
```

### 3. Batch Content Monitoring
```
ç”¨æˆ·: æ‰¹é‡è·å–è¿™10ç¯‡æ–‡ç« çš„æ‘˜è¦
AI: [calls batch_crawl_articles] å·²è·å–10ç¯‡æ–‡ç« ...
```

## Configuration

### Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `DOWNLOAD_IMAGES` | `true` | Download article images |
| `WAIT_TIME` | `10` | Page load timeout (seconds) |
| `OUTPUT_DIR` | `./downloads` | Image download directory |

### Chrome Requirements

The crawler uses Selenium with Chrome. On first run, it will automatically download the appropriate ChromeDriver via `webdriver-manager`.

For headless servers (like VPC), ensure Chrome is installed:

```bash
# Ubuntu/Debian
sudo apt-get install chromium-browser

# Or install Google Chrome
wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
sudo dpkg -i google-chrome-stable_current_amd64.deb
```

## Testing

### Test with the built-in client:

```bash
python src/mcp_weixin_spider/client.py
```

This opens an interactive session where you can test all tools.

### Test the crawler directly:

```bash
python weixin_spider_simple.py
# Enter a WeChat article URL when prompted
```

## Extracted Data

Example output from `crawl_weixin_article`:

```json
{
  "url": "https://mp.weixin.qq.com/s/...",
  "title": "å‘Šåˆ«å¤åˆ¶ç²˜è´´ï¼ç”¨MCPè®©AIç›´æ¥è¯»å–å¾®ä¿¡å…¬ä¼—å·",
  "author": "ç²¾ç¥æŠ–æ“ç‹å¤§é¹",
  "account_name": "ç²¾ç¥æŠ–æ“ç‹å¤§é¹",
  "publish_date": "2025-07-02",
  "content_text": "ä½ æœ‰æ²¡æœ‰é‡åˆ°è¿‡è¿™ç§åœºæ™¯...",
  "content_html": "<div>...</div>",
  "word_count": 1234,
  "images": [
    {
      "index": 0,
      "url": "https://mmbiz.qpic.cn/...",
      "local_path": "./downloads/abc123/image_000.jpg"
    }
  ],
  "crawl_timestamp": "2026-02-03T10:30:00"
}
```

## Limitations & Anti-Bot Protection

âš ï¸ **WeChat has sophisticated anti-bot detection:**

- **Verification pages**: WeChat shows "ç¯å¢ƒå¼‚å¸¸" (environment abnormal) for automated access
- **IP blocking**: Datacenter IPs are quickly blocked
- **Rate limiting**: Aggressive limits on request frequency

### Workarounds

**1. Use saved browser state (recommended):**
```bash
# Login manually in headed mode first
agent-browser --headed open https://mp.weixin.qq.com
# Complete any verification, then save state
agent-browser state save weixin-auth.json

# Later, load saved state
agent-browser state load weixin-auth.json
```

**2. Use residential proxy:**
```bash
agent-browser --proxy http://residential-proxy:port open <url>
```

**3. Rate limiting best practices:**
- Wait 10-30 seconds between requests
- Limit to 10-20 articles per hour
- Use random delays

### Other Limitations

- **Login required**: Some articles require WeChat login
- **Dynamic content**: Complex interactive content may not fully render
- **Image expiry**: Downloaded images are point-in-time snapshots

### References

- [WeChat Scraping Guide](https://scrapingrobot.com/blog/wechat-scraping/) - Residential proxies recommended
- [Anti-Bot Bypass Methods](https://scrapeops.io/web-scraping-playbook/how-to-bypass-antibots/)

## Contributing

PRs welcome! Please:
1. Use `black` for formatting
2. Add tests for new features
3. Update README for API changes

## License

MIT

## Credits

Inspired by [ç²¾ç¥æŠ–æ“ç‹å¤§é¹'s WeChat article](https://mp.weixin.qq.com/s/...) on MCP + crawler integration.

Built with:
- [MCP Python SDK](https://github.com/anthropics/mcp)
- [Selenium](https://www.selenium.dev/)
- [FastMCP](https://github.com/anthropics/mcp)
